{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32291ccb",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc4ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e:\\Projects & Temp\\GitHub\\thesis\\RQ3\n",
      "e:\\Projects & Temp\\GitHub\\thesis\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# The code below uses few-shot learning to generalize a fine-tuned model on another task.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, SwinForImageClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from transformers import pipeline\n",
    "from torch.utils.data import Subset\n",
    "import random\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(\"..\") # have to go up one directory, can also use os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "# CUDA check \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb8a8b",
   "metadata": {},
   "source": [
    "### Define Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba038e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model\n",
    "model_path = './sdxl-fine-tune'\n",
    "# model_path = './sdxl-fine-tune-art'\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "classifier = pipeline(\"image-classification\", model=model_path, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Choose dataset\n",
    "# dataset_path = 'archive/datasets/faces_512x512'\n",
    "dataset_path = 'archive/datasets/art_512x512'\n",
    "\n",
    "ds = load_dataset(\"imagefolder\", data_dir=dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe4e415",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba6f131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform images to model input\n",
    "def transform(image_batch):\n",
    "    inputs = processor(images=image_batch['image'], return_tensors=\"pt\")\n",
    "    inputs['labels'] = torch.tensor(image_batch['label']).to(device)  # Ensure labels are tensors\n",
    "    inputs['pixel_values'] = inputs['pixel_values'].to(device) \n",
    "    return inputs\n",
    "\n",
    "ds_transform = ds.with_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2643af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dicts into tensors\n",
    "def collate_fn(batch):\n",
    "    return {\n",
    "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]).to(device),\n",
    "        'labels': torch.tensor([x['labels'] for x in batch]).to(device)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d84bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "acc_metric = evaluate.load('accuracy')\n",
    "f1_metric = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(p):\n",
    "    acc = acc_metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n",
    "    f1 = f1_metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n",
    "    return {\"Accuracy\": acc[\"accuracy\"], \"F1\": f1[\"f1\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c272eba",
   "metadata": {},
   "source": [
    "### Create Few-Shot Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76fd4f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_few_shot_set(dataset, set_size, seed):\n",
    "    random.seed(seed)\n",
    "\n",
    "    label0 = dataset['train']['label']['0']\n",
    "    label1 = dataset['train']['label']['1']\n",
    "\n",
    "    label0_indices = [i for i, x in enumerate(dataset['train']['label']) if x == label0]\n",
    "    label1_indices = [i for i, x in enumerate(dataset['train']['label']) if x == label1]\n",
    "\n",
    "    # get equal number of samples from each class\n",
    "    newset0_indices = random.sample(label0_indices, set_size // 2)\n",
    "    newset1_indices = random.sample(label1_indices, set_size // 2)\n",
    "    newset_indices = newset0_indices + newset1_indices\n",
    "\n",
    "    random.shuffle(newset_indices)\n",
    "\n",
    "    few_shot_train = Subset(dataset['train'], newset_indices)\n",
    "    val_set = dataset['val'] # can use the full validation set\n",
    "\n",
    "    return few_shot_train, val_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d53a737",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb66df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shot_train, val_set = create_few_shot_set(ds, set_size = 10, seed = 42)\n",
    "\n",
    "# Use current dataset to extract the labels\n",
    "labels = ds['train'].features['label'].names\n",
    "print(labels[0:2])\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SwinForImageClassification.from_pretrained(\n",
    "    model_path, \n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f446e",
   "metadata": {},
   "source": [
    "### Prepare Model For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing earlier layers\n",
    "\n",
    "\n",
    "# Training arguments\n",
    "\n",
    "\n",
    "# Trainer \n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
