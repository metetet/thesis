{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32291ccb",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bc4ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# The code below uses few-shot learning to generalize a fine-tuned model on another task.\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, SwinForImageClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "from datasets import load_dataset, DatasetDict\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from torchinfo import summary\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(\"..\") # have to go up one directory, can also use os.chdir(\"..\")\n",
    "print(os.getcwd())\n",
    "\n",
    "# CUDA check \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befb8a8b",
   "metadata": {},
   "source": [
    "### Define Model and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba038e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 12800\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 1600\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 1600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Choose model\n",
    "model_path = './sdxl-fine-tune'\n",
    "# model_path = './sdxl-fine-tune-art'\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(model_path)\n",
    "#classifier = pipeline(\"image-classification\", model=model_path, device=0 if torch.cuda.is_available() else -1)\n",
    "\n",
    "# Choose dataset\n",
    "# dataset_path = 'archive/datasets/faces_512x512'\n",
    "dataset_path = 'archive/datasets/art_512x512'\n",
    "\n",
    "ds = load_dataset(\"imagefolder\", data_dir=dataset_path)\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e923ede9",
   "metadata": {},
   "source": [
    "### Custom Dataset Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cb1891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the life of me i couldn't get the code to work with the normal huggingface dataset (despite the\n",
    "# fact that the logic IS IDENTICAL to rq2_finetuning, but i digress) so here's a custom dataset class)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, processor, device):\n",
    "        self.dataset = hf_dataset\n",
    "        self.processor = processor\n",
    "        self.device = device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "    # manaully processes each image so pixel values are always returned ('image' is no longer needed for Trainer)\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataset[idx]\n",
    "        inputs = self.processor(images=item['image'], return_tensors=\"pt\")\n",
    "        return {\n",
    "            'pixel_values': inputs['pixel_values'].squeeze(0),\n",
    "            'labels': torch.tensor(item['label'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe4e415",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f2643af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn dicts into tensors\n",
    "def collate_fn(batch):\n",
    "    pixel_values = torch.stack([x['pixel_values'] for x in batch])\n",
    "    labels = torch.tensor([x['labels'] for x in batch])\n",
    "    return {\n",
    "        'pixel_values': pixel_values.to(device),\n",
    "        'labels': labels.to(device)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "40d84bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metrics\n",
    "acc_metric = evaluate.load('accuracy')\n",
    "f1_metric = evaluate.load('f1')\n",
    "\n",
    "def compute_metrics(p):\n",
    "    acc = acc_metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n",
    "    f1 = f1_metric.compute(predictions=np.argmax(p.predictions, axis=1), references=p.label_ids)\n",
    "    return {\"Accuracy\": acc[\"accuracy\"], \"F1\": f1[\"f1\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c272eba",
   "metadata": {},
   "source": [
    "### Create Few-Shot Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "76fd4f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "<class 'datasets.dataset_dict.DatasetDict'>\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 50\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 1600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "def create_few_shot_set(dataset, set_size, seed): # set_size = 10 -> 5-shot learning (2 classes)\n",
    "    random.seed(seed)\n",
    "\n",
    "    newset_indices = []\n",
    "\n",
    "    label0_indices = [i for i, label in enumerate(dataset['train']['label']) if label == 0]\n",
    "    label1_indices = [i for i, label in enumerate(dataset['train']['label']) if label == 1]\n",
    "\n",
    "    # get equal number of samples from each class\n",
    "    newset0_indices = random.sample(label0_indices, set_size // 2)\n",
    "    newset1_indices = random.sample(label1_indices, set_size // 2)\n",
    "    newset_indices = newset0_indices + newset1_indices\n",
    "\n",
    "    random.shuffle(newset_indices)\n",
    "\n",
    "    few_shot_train = dataset['train'].select(newset_indices)\n",
    "    val_set = dataset['validation'] # can use the full validation set\n",
    "\n",
    "    return DatasetDict({\n",
    "        'train': few_shot_train,\n",
    "        'validation': val_set\n",
    "    })\n",
    "\n",
    "print(type(ds))\n",
    "\n",
    "few_shot_ds = create_few_shot_set(ds, set_size=50, seed=44)\n",
    "\n",
    "print(type(few_shot_ds))\n",
    "print(few_shot_ds)\n",
    "\n",
    "train_dataset = CustomDataset(few_shot_ds['train'], processor, device)\n",
    "val_dataset = CustomDataset(few_shot_ds['validation'], processor, device)\n",
    "\n",
    "# sample = train_dataset[0]\n",
    "# print(\"Pixel values shape:\", sample['pixel_values'].shape)\n",
    "# print(\"Label:\", sample['labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d53a737",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fb66df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1']\n"
     ]
    }
   ],
   "source": [
    "# Use current dataset to extract the labels (doesn't really matter which dataset we use)\n",
    "labels = ds['train'].features['label'].names\n",
    "print(labels[0:2])\n",
    "\n",
    "# Load the pre-trained model\n",
    "model = SwinForImageClassification.from_pretrained(\n",
    "    model_path, \n",
    "    num_labels=len(labels),\n",
    "    id2label={str(i): c for i, c in enumerate(labels)},\n",
    "    label2id={c: str(i) for i, c in enumerate(labels)}\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525f446e",
   "metadata": {},
   "source": [
    "### Prepare Model For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bd5bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing earlier layers\n",
    "print(summary(model, input_size=(1, 3, 224, 224)))\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False # freeze all layers\n",
    "\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True # unfreeze the classifier layer\n",
    "\n",
    "for param in model.swin.encoder.layers[-1].parameters():\n",
    "    param.requires_grad = True # unfreeze the last layer of the encoder\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    if \"layernorm\" in name.lower():\n",
    "        param.requires_grad = True # unfreeze layernorm layers \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c11d040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_path + \"_few_shot\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=10, # increase num of epochs for longer training with smaller LR\n",
    "    learning_rate=5e-6, # need low learning rate to avoid forgetting of original dataset stuff\n",
    "    weight_decay=1e-4, # adds regularization to all layers, can help generalize better (?)\n",
    "    logging_dir=\"./logs\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_steps=1,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"none\",\n",
    "    dataloader_pin_memory=False, # causes runtime error otherwise\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc0e8095",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\metet\\AppData\\Local\\Temp\\ipykernel_24480\\1595343547.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: misaligned address\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EarlyStoppingCallback\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Trainer \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m trainer = \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m#callbacks=[EarlyStoppingCallback(early_stopping_patience=15)],\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:457\u001b[39m, in \u001b[36mTrainer.__init__\u001b[39m\u001b[34m(self, model, args, data_collator, train_dataset, eval_dataset, processing_class, model_init, compute_loss_func, compute_metrics, callbacks, optimizers, optimizer_cls_and_kwargs, preprocess_logits_for_metrics)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28mself\u001b[39m.compute_loss_func = compute_loss_func\n\u001b[32m    456\u001b[39m \u001b[38;5;66;03m# Seed must be set before instantiating the model when using model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m457\u001b[39m enable_full_determinism(\u001b[38;5;28mself\u001b[39m.args.seed) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.full_determinism \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mset_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[38;5;28mself\u001b[39m.hp_name = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[38;5;28mself\u001b[39m.deepspeed = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer_utils.py:105\u001b[39m, in \u001b[36mset_seed\u001b[39m\u001b[34m(seed, deterministic)\u001b[39m\n\u001b[32m    103\u001b[39m np.random.seed(seed)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    106\u001b[39m     torch.cuda.manual_seed_all(seed)\n\u001b[32m    107\u001b[39m     \u001b[38;5;66;03m# ^^ safe to call this function even if cuda is not available\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_compile.py:51\u001b[39m, in \u001b[36m_disable_dynamo.<locals>.inner\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     48\u001b[39m     disable_fn = torch._dynamo.disable(fn, recursive)\n\u001b[32m     49\u001b[39m     fn.__dynamo_disable = disable_fn  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:856\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    854\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m856\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    858\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\random.py:46\u001b[39m, in \u001b[36mmanual_seed\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcuda\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.cuda._is_in_bad_fork():\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmps\u001b[39;00m\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch.mps._is_in_bad_fork():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\random.py:131\u001b[39m, in \u001b[36mmanual_seed_all\u001b[39m\u001b[34m(seed)\u001b[39m\n\u001b[32m    128\u001b[39m         default_generator = torch.cuda.default_generators[i]\n\u001b[32m    129\u001b[39m         default_generator.manual_seed(seed)\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[43m_lazy_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_all\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\__init__.py:308\u001b[39m, in \u001b[36m_lazy_call\u001b[39m\u001b[34m(callable, **kwargs)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m _initialization_lock:\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m         \u001b[38;5;28;43mcallable\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    310\u001b[39m         \u001b[38;5;66;03m# TODO(torch_deploy): this accesses linecache, which attempts to read the\u001b[39;00m\n\u001b[32m    311\u001b[39m         \u001b[38;5;66;03m# file system to get traceback info. Patch linecache or do something\u001b[39;00m\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# else here if this ends up being important.\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;28;01mglobal\u001b[39;00m _lazy_seed_tracker\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\cuda\\random.py:129\u001b[39m, in \u001b[36mmanual_seed_all.<locals>.cb\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(device_count()):\n\u001b[32m    128\u001b[39m     default_generator = torch.cuda.default_generators[i]\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m     \u001b[43mdefault_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmanual_seed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: misaligned address\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from transformers import EarlyStoppingCallback\n",
    "\n",
    "# Trainer \n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor,\n",
    "    #callbacks=[EarlyStoppingCallback(early_stopping_patience=15)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec3eaf1",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e771442d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='92' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 92/130 05:20 < 02:15, 0.28 it/s, Epoch 7/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.657600</td>\n",
       "      <td>4.898038</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>0.019449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5.805400</td>\n",
       "      <td>4.561170</td>\n",
       "      <td>0.249375</td>\n",
       "      <td>0.016380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.985200</td>\n",
       "      <td>4.269258</td>\n",
       "      <td>0.258125</td>\n",
       "      <td>0.016570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4.823100</td>\n",
       "      <td>4.025722</td>\n",
       "      <td>0.264375</td>\n",
       "      <td>0.016708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>6.059500</td>\n",
       "      <td>3.820611</td>\n",
       "      <td>0.271875</td>\n",
       "      <td>0.016878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.686200</td>\n",
       "      <td>3.657890</td>\n",
       "      <td>0.276250</td>\n",
       "      <td>0.016978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='155' max='400' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [155/400 00:18 < 00:29, 8.18 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 128}\n",
      "  warnings.warn(\n",
      "c:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 128}\n",
      "  warnings.warn(\n",
      "c:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 128}\n",
      "  warnings.warn(\n",
      "c:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 128}\n",
      "  warnings.warn(\n",
      "c:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 128}\n",
      "  warnings.warn(\n",
      "c:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\configuration_utils.py:393: UserWarning: Some non-default generation parameters are set in the model config. These should go into either a) `model.generation_config` (as opposed to `model.config`); OR b) a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model).This warning will become an exception in the future.\n",
      "Non-default generation parameters: {'max_length': 128}\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: misaligned address\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_results = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m trainer.save_model()\n\u001b[32m      3\u001b[39m trainer.log_metrics(\u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m, train_results.metrics)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:2661\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2658\u001b[39m     \u001b[38;5;28mself\u001b[39m.control.should_training_stop = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   2660\u001b[39m \u001b[38;5;28mself\u001b[39m.control = \u001b[38;5;28mself\u001b[39m.callback_handler.on_epoch_end(args, \u001b[38;5;28mself\u001b[39m.state, \u001b[38;5;28mself\u001b[39m.control)\n\u001b[32m-> \u001b[39m\u001b[32m2661\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2662\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\n\u001b[32m   2663\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2665\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DebugOption.TPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.debug:\n\u001b[32m   2666\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_xla_available():\n\u001b[32m   2667\u001b[39m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3096\u001b[39m, in \u001b[36mTrainer._maybe_log_save_evaluate\u001b[39m\u001b[34m(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate)\u001b[39m\n\u001b[32m   3094\u001b[39m metrics = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   3095\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.control.should_evaluate:\n\u001b[32m-> \u001b[39m\u001b[32m3096\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3097\u001b[39m     is_new_best_metric = \u001b[38;5;28mself\u001b[39m._determine_best_metric(metrics=metrics, trial=trial)\n\u001b[32m   3099\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.save_strategy == SaveStrategy.BEST:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:3045\u001b[39m, in \u001b[36mTrainer._evaluate\u001b[39m\u001b[34m(self, trial, ignore_keys_for_eval, skip_scheduler)\u001b[39m\n\u001b[32m   3044\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, ignore_keys_for_eval, skip_scheduler=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m3045\u001b[39m     metrics = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3046\u001b[39m     \u001b[38;5;28mself\u001b[39m._report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m.state.global_step, metrics)\n\u001b[32m   3048\u001b[39m     \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:4154\u001b[39m, in \u001b[36mTrainer.evaluate\u001b[39m\u001b[34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4151\u001b[39m start_time = time.time()\n\u001b[32m   4153\u001b[39m eval_loop = \u001b[38;5;28mself\u001b[39m.prediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.args.use_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.evaluation_loop\n\u001b[32m-> \u001b[39m\u001b[32m4154\u001b[39m output = \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4155\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvaluation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[32m   4159\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   4160\u001b[39m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4161\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4162\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4164\u001b[39m total_batch_size = \u001b[38;5;28mself\u001b[39m.args.eval_batch_size * \u001b[38;5;28mself\u001b[39m.args.world_size\n\u001b[32m   4165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_jit_compilation_time\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output.metrics:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\trainer.py:4370\u001b[39m, in \u001b[36mTrainer.evaluation_loop\u001b[39m\u001b[34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[39m\n\u001b[32m   4368\u001b[39m     labels = \u001b[38;5;28mself\u001b[39m.accelerator.pad_across_processes(labels, dim=\u001b[32m1\u001b[39m, pad_index=-\u001b[32m100\u001b[39m)\n\u001b[32m   4369\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4370\u001b[39m     logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   4371\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.preprocess_logits_for_metrics \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   4372\u001b[39m         logits = \u001b[38;5;28mself\u001b[39m.preprocess_logits_for_metrics(logits, labels)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\accelerator.py:2813\u001b[39m, in \u001b[36mAccelerator.pad_across_processes\u001b[39m\u001b[34m(self, tensor, dim, pad_index, pad_first)\u001b[39m\n\u001b[32m   2780\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpad_across_processes\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, dim=\u001b[32m0\u001b[39m, pad_index=\u001b[32m0\u001b[39m, pad_first=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m   2781\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2782\u001b[39m \u001b[33;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[32m   2783\u001b[39m \u001b[33;03m    they can safely be gathered.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2811\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m   2812\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2813\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_first\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\operations.py:403\u001b[39m, in \u001b[36mchained_operation.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args, **kwargs):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    404\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m DistributedOperationException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    405\u001b[39m         operation = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction.\u001b[34m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\operations.py:673\u001b[39m, in \u001b[36mpad_across_processes\u001b[39m\u001b[34m(tensor, dim, pad_index, pad_first)\u001b[39m\n\u001b[32m    670\u001b[39m     new_tensor[indices] = tensor\n\u001b[32m    671\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m new_tensor\n\u001b[32m--> \u001b[39m\u001b[32m673\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_pad_across_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpad_first\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\operations.py:126\u001b[39m, in \u001b[36mrecursively_apply\u001b[39m\u001b[34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[32m    118\u001b[39m         {\n\u001b[32m    119\u001b[39m             k: recursively_apply(\n\u001b[32m   (...)\u001b[39m\u001b[32m    123\u001b[39m         }\n\u001b[32m    124\u001b[39m     )\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m    129\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`. Only nested list/tuple/dicts of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    130\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` should be passed.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    131\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\metet\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\accelerate\\utils\\operations.py:653\u001b[39m, in \u001b[36mpad_across_processes.<locals>._pad_across_processes\u001b[39m\u001b[34m(tensor, dim, pad_index, pad_first)\u001b[39m\n\u001b[32m    650\u001b[39m     dim += \u001b[38;5;28mlen\u001b[39m(tensor.shape)\n\u001b[32m    652\u001b[39m \u001b[38;5;66;03m# Gather all sizes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m653\u001b[39m size = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m    654\u001b[39m sizes = gather(size).cpu()\n\u001b[32m    655\u001b[39m \u001b[38;5;66;03m# Then pad to the maximum size\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: misaligned address\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "train_results = trainer.train()\n",
    "trainer.save_model()\n",
    "trainer.log_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_metrics(\"train\", train_results.metrics)\n",
    "trainer.save_state()\n",
    "\n",
    "metrics = trainer.evaluate(val_dataset)\n",
    "trainer.log_metrics(\"eval\", metrics)\n",
    "trainer.save_metrics(\"eval\", metrics)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
